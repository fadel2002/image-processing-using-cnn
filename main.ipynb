{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import LeakyReLU\n",
    "import seaborn as sns\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,) [1 1 1 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "# weather mapping function\n",
    "def weatherName(i):\n",
    "    if (i == 1):\n",
    "        return \"berembun\"\n",
    "    elif (i == 2):\n",
    "        return \"berkabut\"\n",
    "    elif (i == 3):\n",
    "        return \"hujan es\"\n",
    "    elif (i == 4):\n",
    "        return \"petir\"\n",
    "    elif (i == 5):\n",
    "        return \"hujan\"\n",
    "    elif (i == 6):\n",
    "        return \"pelangi\"\n",
    "    elif (i == 7):\n",
    "        return \"badai pasir\"\n",
    "    else:\n",
    "        return \"salju\"\n",
    "\n",
    "# weather code mapping function for training data\n",
    "def weatherTrain(i):\n",
    "    if (i < 200):\n",
    "        return 1\n",
    "    elif (i < 400):\n",
    "        return 2\n",
    "    elif (i < 600):\n",
    "        return 3\n",
    "    elif (i < 800):\n",
    "        return 4\n",
    "    elif (i < 1000):\n",
    "        return 5\n",
    "    elif (i < 1200):\n",
    "        return 6\n",
    "    elif (i < 1400):\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "\n",
    "# mapping for data training results (y_train)\n",
    "y_train = np.array([weatherTrain(index) for index in range(0, 1600)], dtype=int)\n",
    "y_train.reshape(-1,)\n",
    "print(y_train.shape, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 150, 200, 3) (1600,)\n"
     ]
    }
   ],
   "source": [
    "# data image preprocessing\n",
    "# input training dataset to numpy array\n",
    "dew = np.array([resize(np.array(Image.open('./Train/dew/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/dew')], dtype=float)\n",
    "\n",
    "fogsmog = np.array([resize(np.array(Image.open('./Train/fogsmog/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/fogsmog')], dtype=float)\n",
    "\n",
    "join = np.append(dew, fogsmog,  0)\n",
    "\n",
    "hail = np.array([resize(np.array(Image.open('./Train/hail/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/hail')], dtype=float)\n",
    "\n",
    "join = np.append(join, hail,  0)\n",
    "\n",
    "lightning = np.array([resize(np.array(Image.open('./Train/lightning/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/lightning')], dtype=float)\n",
    "\n",
    "join = np.append(join, lightning,  0)\n",
    "\n",
    "rain = np.array([resize(np.array(Image.open('./Train/rain/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/rain')], dtype=float)\n",
    "\n",
    "join = np.append(join, rain,  0)\n",
    "\n",
    "rainbow = np.array([resize(np.array(Image.open('./Train/rainbow/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/rainbow')], dtype=float)\n",
    "\n",
    "join = np.append(join, rainbow,  0)\n",
    "\n",
    "sandstorm = np.array([resize(np.array(Image.open('./Train/sandstorm/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/sandstorm')], dtype=float)\n",
    "\n",
    "join = np.append(join, sandstorm,  0)\n",
    "\n",
    "snow = np.array([resize(np.array(Image.open('./Train/snow/' + filename)) ,(150,200,3)) for filename in os.listdir('./Train/snow')], dtype=float)\n",
    "\n",
    "# mapping for data training (X_train)\n",
    "X_train = np.append(join, snow,  0)\n",
    "\n",
    "# check data training shape\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 24s 467ms/step - loss: 1.6545 - accuracy: 0.4019\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 23s 451ms/step - loss: 1.1625 - accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 23s 460ms/step - loss: 0.9492 - accuracy: 0.6919\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 23s 455ms/step - loss: 0.7969 - accuracy: 0.7362\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 23s 461ms/step - loss: 0.7237 - accuracy: 0.7613\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 23s 453ms/step - loss: 0.6467 - accuracy: 0.7856\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 23s 453ms/step - loss: 0.5768 - accuracy: 0.7937\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 23s 454ms/step - loss: 0.5014 - accuracy: 0.8319\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 23s 452ms/step - loss: 0.4256 - accuracy: 0.8619\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 23s 461ms/step - loss: 0.3772 - accuracy: 0.8719\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 23s 464ms/step - loss: 0.3713 - accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 0.3274 - accuracy: 0.8938\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 22s 444ms/step - loss: 0.2251 - accuracy: 0.9262\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 22s 447ms/step - loss: 0.1867 - accuracy: 0.9331\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 22s 448ms/step - loss: 0.1528 - accuracy: 0.9481\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 22s 449ms/step - loss: 0.1637 - accuracy: 0.9438\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 22s 449ms/step - loss: 0.1532 - accuracy: 0.9481\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 22s 448ms/step - loss: 0.0965 - accuracy: 0.9656\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.1014 - accuracy: 0.9663\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 23s 453ms/step - loss: 0.1919 - accuracy: 0.9381\n"
     ]
    }
   ],
   "source": [
    "# cnn model\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 200, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# using adam for optimizer function and sparse categorical crossentropy for loss function \n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "# using 20 epochs\n",
    "history = cnn.fit(X_train, y_train, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d99a3f7b344b3c3107482760db15f42178bfad658d282ab0a919b76809e13cb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
